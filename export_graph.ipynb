{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import wandb\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.cuda import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshivamshrirao\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/clip_classifier/wandb/run-20220525_065443-3kuwd2c3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"https://wandb.ai/shivamshrirao/clip_cls_36/runs/3kuwd2c3\" target=\"_blank\">rosy-galaxy-192</a></strong> to <a href=\"https://wandb.ai/shivamshrirao/clip_cls_36\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"clip_cls_36\", id=\"3kuwd2c3\", resume='must')\n",
    "CONFIG = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cache = f\"{CONFIG['clip_type']}_features.pth\"\n",
    "ft_dict = torch.load(features_cache)\n",
    "train_features = ft_dict[\"train_features\"]\n",
    "train_labels = ft_dict[\"train_labels\"]\n",
    "test_features = ft_dict[\"test_features\"]\n",
    "test_labels = ft_dict[\"test_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35],\n",
       "        device='cuda:0'),\n",
       " tensor([3827, 3798, 3831, 3780, 3758, 3755, 3745, 3763, 3598, 3593, 3585, 3582,\n",
       "         3594, 3561, 3560, 3543, 3575, 3544, 3542, 3541, 3560, 3558, 3563, 3558,\n",
       "         3536, 3574, 3532, 3567, 3543, 3528, 3524, 3534, 3566, 3554, 3544, 3568],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(train_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35],\n",
       "        device='cuda:0'),\n",
       " tensor([189, 200, 166, 179, 199, 212, 209, 196, 185, 186, 188, 186, 176, 202,\n",
       "         199, 210, 169, 203, 189, 199, 181, 181, 174, 179, 190, 170, 211, 173,\n",
       "         191, 204, 210, 201, 170, 182, 184, 192], device='cuda:0'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(test_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnv = {}\n",
    "# for i in range(8):\n",
    "#     x = i*45\n",
    "#     if i%2:\n",
    "#         cnv[x-5] = cnv[x+5] = i\n",
    "#     else:\n",
    "#         cnv[(x-10)%360] = cnv[x] = cnv[(x+10)%360] = i\n",
    "# cnv = {k//10:v for k,v in cnv.items()}\n",
    "\n",
    "# for i in range(len(train_labels)):\n",
    "#     try:\n",
    "#         train_labels[i] = cnv[train_labels[i].item()]\n",
    "#     except KeyError:\n",
    "#         train_labels[i] = 8\n",
    "# for i in range(len(test_labels)):\n",
    "#     try:\n",
    "#         test_labels[i] = cnv[test_labels[i].item()]\n",
    "#     except KeyError:\n",
    "#         test_labels[i] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuickGELU(nn.Module):\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return x * torch.sigmoid(1.702 * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_activation = {\n",
    "    'q_gelu': QuickGELU,\n",
    "    'relu': nn.ReLU,\n",
    "    'elu': nn.ELU,\n",
    "    'leaky_relu': nn.LeakyReLU\n",
    "}\n",
    "\n",
    "# cls_head = nn.Sequential(\n",
    "#     # nn.Dropout(CONFIG[\"dropout\"]),\n",
    "#     nn.Linear(len(train_features[0]), CONFIG[\"hid_dim\"]),\n",
    "# #     get_activation[CONFIG[\"activation\"]](),\n",
    "#     get_activation['relu'](),\n",
    "#     nn.Dropout(CONFIG[\"dropout\"]),\n",
    "#     nn.Linear(CONFIG[\"hid_dim\"], num_classes)\n",
    "# )\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mean = 255 * torch.tensor([0.485, 0.456, 0.406], dtype=torch.float16, device=device).reshape(1, 3, 1, 1)\n",
    "        self.std = 255 * torch.tensor([0.229, 0.224, 0.225], dtype=torch.float16, device=device).reshape(1, 3, 1, 1)\n",
    "        self.clip_model, preprocess = clip.load(CONFIG[\"clip_type\"], device)\n",
    "        self.clip_model = self.clip_model.float()\n",
    "        self.cls_head = nn.Sequential(\n",
    "            # nn.Dropout(CONFIG[\"dropout\"]),\n",
    "            nn.LazyLinear(CONFIG[\"hid_dim\"]),\n",
    "            get_activation[CONFIG[\"activation\"]](),\n",
    "            nn.Dropout(CONFIG[\"dropout\"]),\n",
    "            nn.Linear(CONFIG[\"hid_dim\"], num_classes)\n",
    "        ).to(device).train()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0,3,1,2)\n",
    "        x = (x - self.mean).div_(self.std)\n",
    "        x = self.clip_model.visual(x)\n",
    "        x = self.cls_head(x)\n",
    "        return x\n",
    "model = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"weights/new2.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 512])\n"
     ]
    }
   ],
   "source": [
    "data = train_features[:256]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 224, 224, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "im_path = \"/home/ubuntu/clip_classifier/data/rbg_test/1_VCC_1034828_24_1613203232.jpg.jpg\"\n",
    "im = cv2.imread(im_path, cv2.IMREAD_GRAYSCALE)\n",
    "im = cv2.cvtColor(im, cv2.COLOR_GRAY2RGB)\n",
    "im = cv2.resize(im,(224,224))[None]\n",
    "image = torch.from_numpy(im).cuda()\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wrapped_linear_model(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def forward(self, data, fp16=True):\n",
    "        with amp.autocast(enabled=fp16):\n",
    "            x = self.model(data)\n",
    "            x = torch.softmax(x, dim=1)\n",
    "            # x = x.argmax(dim=1,keepdim=True)\n",
    "        return x\n",
    "wrp_model = Wrapped_linear_model(model).to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 36]) torch.float32\n",
      "CPU times: user 9.62 ms, sys: 694 µs, total: 10.3 ms\n",
      "Wall time: 9.05 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "torch.cuda.synchronize()\n",
    "with torch.no_grad():\n",
    "    svd_out = wrp_model(image, True)\n",
    "torch.cuda.synchronize()\n",
    "print(svd_out.shape, svd_out.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    data: Tensor) -> Tensor:\n",
      "  x = torch.permute(data, [0, 3, 1, 2])\n",
      "  input = torch.div_(torch.sub(x, CONSTANTS.c0), CONSTANTS.c1)\n",
      "  _0 = torch.conv2d(input, CONSTANTS.c2, None, [32, 32])\n",
      "  _1 = [torch.size(_0, 0), torch.size(_0, 1), -1]\n",
      "  x0 = torch.reshape(_0, _1)\n",
      "  x1 = torch.permute(x0, [0, 2, 1])\n",
      "  _2 = [torch.size(x1, 0), 1, torch.size(x1, 2)]\n",
      "  _3 = torch.zeros(_2, dtype=5, layout=None, device=torch.device(\"cuda:0\"), pin_memory=False)\n",
      "  x2 = torch.cat([torch.add(CONSTANTS.c3, _3), x1], 1)\n",
      "  x3 = torch.add(x2, CONSTANTS.c4)\n",
      "  input0 = torch.to(x3, 6)\n",
      "  ret = torch.layer_norm(input0, [768], CONSTANTS.c5, CONSTANTS.c6)\n",
      "  x4 = torch.to(ret, 5)\n",
      "  x5 = torch.permute(x4, [1, 0, 2])\n",
      "  input1 = torch.to(x5, 6)\n",
      "  ret0 = torch.layer_norm(input1, [768], CONSTANTS.c7, CONSTANTS.c8)\n",
      "  query = torch.to(ret0, 5)\n",
      "  _4 = torch.size(query, 0)\n",
      "  _5 = torch.size(query, 1)\n",
      "  bsz = ops.prim.NumToTensor(_5)\n",
      "  _6 = torch.size(query, 2)\n",
      "  embed_dim = ops.prim.NumToTensor(_6)\n",
      "  head_dim = torch.div(embed_dim, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _7 = int(head_dim)\n",
      "  _8 = torch.add(torch.matmul(query, CONSTANTS.c10), CONSTANTS.c11)\n",
      "  q, k, v, = torch.chunk(_8, 3, -1)\n",
      "  _9 = torch.contiguous(q)\n",
      "  _10 = int(torch.mul(bsz, CONSTANTS.c9))\n",
      "  q0 = torch.transpose(torch.view(_9, [_4, _10, _7]), 0, 1)\n",
      "  _11 = torch.view(torch.contiguous(k), [torch.size(k, 0), _10, _7])\n",
      "  k0 = torch.transpose(_11, 0, 1)\n",
      "  _12 = torch.view(torch.contiguous(v), [torch.size(v, 0), _10, _7])\n",
      "  v0 = torch.transpose(_12, 0, 1)\n",
      "  q1 = torch.div(q0, CONSTANTS.c12)\n",
      "  input2 = torch.bmm(q1, torch.transpose(k0, -2, -1))\n",
      "  attn = torch.softmax(input2, -1, 6)\n",
      "  attn_output = torch.bmm(torch.to(attn, 5), v0)\n",
      "  _13 = torch.contiguous(torch.transpose(attn_output, 0, 1))\n",
      "  attn_output0 = torch.view(_13, [_4, _5, _6])\n",
      "  _14 = torch.matmul(attn_output0, CONSTANTS.c13)\n",
      "  x6 = torch.add(x5, torch.add(_14, CONSTANTS.c14))\n",
      "  input3 = torch.to(x6, 6)\n",
      "  ret1 = torch.layer_norm(input3, [768], CONSTANTS.c15, CONSTANTS.c16)\n",
      "  input4 = torch.to(ret1, 5)\n",
      "  _15 = torch.add(torch.matmul(input4, CONSTANTS.c17), CONSTANTS.c18)\n",
      "  _16 = torch.sigmoid(torch.mul(_15, CONSTANTS.c19))\n",
      "  input5 = torch.mul(_15, _16)\n",
      "  _17 = torch.add(torch.matmul(input5, CONSTANTS.c20), CONSTANTS.c21)\n",
      "  x7 = torch.add(x6, _17)\n",
      "  input6 = torch.to(x7, 6)\n",
      "  ret2 = torch.layer_norm(input6, [768], CONSTANTS.c22, CONSTANTS.c23)\n",
      "  query0 = torch.to(ret2, 5)\n",
      "  _18 = torch.size(query0, 0)\n",
      "  _19 = torch.size(query0, 1)\n",
      "  bsz0 = ops.prim.NumToTensor(_19)\n",
      "  _20 = torch.size(query0, 2)\n",
      "  embed_dim0 = ops.prim.NumToTensor(_20)\n",
      "  head_dim0 = torch.div(embed_dim0, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _21 = int(head_dim0)\n",
      "  _22 = torch.add(torch.matmul(query0, CONSTANTS.c24), CONSTANTS.c25)\n",
      "  q2, k1, v1, = torch.chunk(_22, 3, -1)\n",
      "  _23 = torch.contiguous(q2)\n",
      "  _24 = int(torch.mul(bsz0, CONSTANTS.c9))\n",
      "  q3 = torch.transpose(torch.view(_23, [_18, _24, _21]), 0, 1)\n",
      "  _25 = torch.view(torch.contiguous(k1), [torch.size(k1, 0), _24, _21])\n",
      "  k2 = torch.transpose(_25, 0, 1)\n",
      "  _26 = torch.view(torch.contiguous(v1), [torch.size(v1, 0), _24, _21])\n",
      "  v2 = torch.transpose(_26, 0, 1)\n",
      "  q4 = torch.div(q3, CONSTANTS.c12)\n",
      "  input7 = torch.bmm(q4, torch.transpose(k2, -2, -1))\n",
      "  attn0 = torch.softmax(input7, -1, 6)\n",
      "  attn_output1 = torch.bmm(torch.to(attn0, 5), v2)\n",
      "  _27 = torch.contiguous(torch.transpose(attn_output1, 0, 1))\n",
      "  attn_output2 = torch.view(_27, [_18, _19, _20])\n",
      "  _28 = torch.matmul(attn_output2, CONSTANTS.c26)\n",
      "  x8 = torch.add(x7, torch.add(_28, CONSTANTS.c27))\n",
      "  input8 = torch.to(x8, 6)\n",
      "  ret3 = torch.layer_norm(input8, [768], CONSTANTS.c28, CONSTANTS.c29)\n",
      "  input9 = torch.to(ret3, 5)\n",
      "  _29 = torch.add(torch.matmul(input9, CONSTANTS.c30), CONSTANTS.c31)\n",
      "  _30 = torch.sigmoid(torch.mul(_29, CONSTANTS.c19))\n",
      "  input10 = torch.mul(_29, _30)\n",
      "  _31 = torch.add(torch.matmul(input10, CONSTANTS.c32), CONSTANTS.c33)\n",
      "  x9 = torch.add(x8, _31)\n",
      "  input11 = torch.to(x9, 6)\n",
      "  ret4 = torch.layer_norm(input11, [768], CONSTANTS.c34, CONSTANTS.c35)\n",
      "  query1 = torch.to(ret4, 5)\n",
      "  _32 = torch.size(query1, 0)\n",
      "  _33 = torch.size(query1, 1)\n",
      "  bsz1 = ops.prim.NumToTensor(_33)\n",
      "  _34 = torch.size(query1, 2)\n",
      "  embed_dim1 = ops.prim.NumToTensor(_34)\n",
      "  head_dim1 = torch.div(embed_dim1, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _35 = int(head_dim1)\n",
      "  _36 = torch.add(torch.matmul(query1, CONSTANTS.c36), CONSTANTS.c37)\n",
      "  q5, k3, v3, = torch.chunk(_36, 3, -1)\n",
      "  _37 = torch.contiguous(q5)\n",
      "  _38 = int(torch.mul(bsz1, CONSTANTS.c9))\n",
      "  q6 = torch.transpose(torch.view(_37, [_32, _38, _35]), 0, 1)\n",
      "  _39 = torch.view(torch.contiguous(k3), [torch.size(k3, 0), _38, _35])\n",
      "  k4 = torch.transpose(_39, 0, 1)\n",
      "  _40 = torch.view(torch.contiguous(v3), [torch.size(v3, 0), _38, _35])\n",
      "  v4 = torch.transpose(_40, 0, 1)\n",
      "  q7 = torch.div(q6, CONSTANTS.c12)\n",
      "  input12 = torch.bmm(q7, torch.transpose(k4, -2, -1))\n",
      "  attn1 = torch.softmax(input12, -1, 6)\n",
      "  attn_output3 = torch.bmm(torch.to(attn1, 5), v4)\n",
      "  _41 = torch.contiguous(torch.transpose(attn_output3, 0, 1))\n",
      "  attn_output4 = torch.view(_41, [_32, _33, _34])\n",
      "  _42 = torch.matmul(attn_output4, CONSTANTS.c38)\n",
      "  x10 = torch.add(x9, torch.add(_42, CONSTANTS.c39))\n",
      "  input13 = torch.to(x10, 6)\n",
      "  ret5 = torch.layer_norm(input13, [768], CONSTANTS.c40, CONSTANTS.c41)\n",
      "  input14 = torch.to(ret5, 5)\n",
      "  _43 = torch.add(torch.matmul(input14, CONSTANTS.c42), CONSTANTS.c43)\n",
      "  _44 = torch.sigmoid(torch.mul(_43, CONSTANTS.c19))\n",
      "  input15 = torch.mul(_43, _44)\n",
      "  _45 = torch.add(torch.matmul(input15, CONSTANTS.c44), CONSTANTS.c45)\n",
      "  x11 = torch.add(x10, _45)\n",
      "  input16 = torch.to(x11, 6)\n",
      "  ret6 = torch.layer_norm(input16, [768], CONSTANTS.c46, CONSTANTS.c47)\n",
      "  query2 = torch.to(ret6, 5)\n",
      "  _46 = torch.size(query2, 0)\n",
      "  _47 = torch.size(query2, 1)\n",
      "  bsz2 = ops.prim.NumToTensor(_47)\n",
      "  _48 = torch.size(query2, 2)\n",
      "  embed_dim2 = ops.prim.NumToTensor(_48)\n",
      "  head_dim2 = torch.div(embed_dim2, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _49 = int(head_dim2)\n",
      "  _50 = torch.add(torch.matmul(query2, CONSTANTS.c48), CONSTANTS.c49)\n",
      "  q8, k5, v5, = torch.chunk(_50, 3, -1)\n",
      "  _51 = torch.contiguous(q8)\n",
      "  _52 = int(torch.mul(bsz2, CONSTANTS.c9))\n",
      "  q9 = torch.transpose(torch.view(_51, [_46, _52, _49]), 0, 1)\n",
      "  _53 = torch.view(torch.contiguous(k5), [torch.size(k5, 0), _52, _49])\n",
      "  k6 = torch.transpose(_53, 0, 1)\n",
      "  _54 = torch.view(torch.contiguous(v5), [torch.size(v5, 0), _52, _49])\n",
      "  v6 = torch.transpose(_54, 0, 1)\n",
      "  q10 = torch.div(q9, CONSTANTS.c12)\n",
      "  input17 = torch.bmm(q10, torch.transpose(k6, -2, -1))\n",
      "  attn2 = torch.softmax(input17, -1, 6)\n",
      "  attn_output5 = torch.bmm(torch.to(attn2, 5), v6)\n",
      "  _55 = torch.contiguous(torch.transpose(attn_output5, 0, 1))\n",
      "  attn_output6 = torch.view(_55, [_46, _47, _48])\n",
      "  _56 = torch.matmul(attn_output6, CONSTANTS.c50)\n",
      "  x12 = torch.add(x11, torch.add(_56, CONSTANTS.c51))\n",
      "  input18 = torch.to(x12, 6)\n",
      "  ret7 = torch.layer_norm(input18, [768], CONSTANTS.c52, CONSTANTS.c53)\n",
      "  input19 = torch.to(ret7, 5)\n",
      "  _57 = torch.add(torch.matmul(input19, CONSTANTS.c54), CONSTANTS.c55)\n",
      "  _58 = torch.sigmoid(torch.mul(_57, CONSTANTS.c19))\n",
      "  input20 = torch.mul(_57, _58)\n",
      "  _59 = torch.add(torch.matmul(input20, CONSTANTS.c56), CONSTANTS.c57)\n",
      "  x13 = torch.add(x12, _59)\n",
      "  input21 = torch.to(x13, 6)\n",
      "  ret8 = torch.layer_norm(input21, [768], CONSTANTS.c58, CONSTANTS.c59)\n",
      "  query3 = torch.to(ret8, 5)\n",
      "  _60 = torch.size(query3, 0)\n",
      "  _61 = torch.size(query3, 1)\n",
      "  bsz3 = ops.prim.NumToTensor(_61)\n",
      "  _62 = torch.size(query3, 2)\n",
      "  embed_dim3 = ops.prim.NumToTensor(_62)\n",
      "  head_dim3 = torch.div(embed_dim3, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _63 = int(head_dim3)\n",
      "  _64 = torch.add(torch.matmul(query3, CONSTANTS.c60), CONSTANTS.c61)\n",
      "  q11, k7, v7, = torch.chunk(_64, 3, -1)\n",
      "  _65 = torch.contiguous(q11)\n",
      "  _66 = int(torch.mul(bsz3, CONSTANTS.c9))\n",
      "  q12 = torch.transpose(torch.view(_65, [_60, _66, _63]), 0, 1)\n",
      "  _67 = torch.view(torch.contiguous(k7), [torch.size(k7, 0), _66, _63])\n",
      "  k8 = torch.transpose(_67, 0, 1)\n",
      "  _68 = torch.view(torch.contiguous(v7), [torch.size(v7, 0), _66, _63])\n",
      "  v8 = torch.transpose(_68, 0, 1)\n",
      "  q13 = torch.div(q12, CONSTANTS.c12)\n",
      "  input22 = torch.bmm(q13, torch.transpose(k8, -2, -1))\n",
      "  attn3 = torch.softmax(input22, -1, 6)\n",
      "  attn_output7 = torch.bmm(torch.to(attn3, 5), v8)\n",
      "  _69 = torch.contiguous(torch.transpose(attn_output7, 0, 1))\n",
      "  attn_output8 = torch.view(_69, [_60, _61, _62])\n",
      "  _70 = torch.matmul(attn_output8, CONSTANTS.c62)\n",
      "  x14 = torch.add(x13, torch.add(_70, CONSTANTS.c63))\n",
      "  input23 = torch.to(x14, 6)\n",
      "  ret9 = torch.layer_norm(input23, [768], CONSTANTS.c64, CONSTANTS.c65)\n",
      "  input24 = torch.to(ret9, 5)\n",
      "  _71 = torch.add(torch.matmul(input24, CONSTANTS.c66), CONSTANTS.c67)\n",
      "  _72 = torch.sigmoid(torch.mul(_71, CONSTANTS.c19))\n",
      "  input25 = torch.mul(_71, _72)\n",
      "  _73 = torch.add(torch.matmul(input25, CONSTANTS.c68), CONSTANTS.c69)\n",
      "  x15 = torch.add(x14, _73)\n",
      "  input26 = torch.to(x15, 6)\n",
      "  ret10 = torch.layer_norm(input26, [768], CONSTANTS.c70, CONSTANTS.c71)\n",
      "  query4 = torch.to(ret10, 5)\n",
      "  _74 = torch.size(query4, 0)\n",
      "  _75 = torch.size(query4, 1)\n",
      "  bsz4 = ops.prim.NumToTensor(_75)\n",
      "  _76 = torch.size(query4, 2)\n",
      "  embed_dim4 = ops.prim.NumToTensor(_76)\n",
      "  head_dim4 = torch.div(embed_dim4, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _77 = int(head_dim4)\n",
      "  _78 = torch.add(torch.matmul(query4, CONSTANTS.c72), CONSTANTS.c73)\n",
      "  q14, k9, v9, = torch.chunk(_78, 3, -1)\n",
      "  _79 = torch.contiguous(q14)\n",
      "  _80 = int(torch.mul(bsz4, CONSTANTS.c9))\n",
      "  q15 = torch.transpose(torch.view(_79, [_74, _80, _77]), 0, 1)\n",
      "  _81 = torch.view(torch.contiguous(k9), [torch.size(k9, 0), _80, _77])\n",
      "  k10 = torch.transpose(_81, 0, 1)\n",
      "  _82 = torch.view(torch.contiguous(v9), [torch.size(v9, 0), _80, _77])\n",
      "  v10 = torch.transpose(_82, 0, 1)\n",
      "  q16 = torch.div(q15, CONSTANTS.c12)\n",
      "  input27 = torch.bmm(q16, torch.transpose(k10, -2, -1))\n",
      "  attn4 = torch.softmax(input27, -1, 6)\n",
      "  attn_output9 = torch.bmm(torch.to(attn4, 5), v10)\n",
      "  _83 = torch.contiguous(torch.transpose(attn_output9, 0, 1))\n",
      "  attn_output10 = torch.view(_83, [_74, _75, _76])\n",
      "  _84 = torch.matmul(attn_output10, CONSTANTS.c74)\n",
      "  x16 = torch.add(x15, torch.add(_84, CONSTANTS.c75))\n",
      "  input28 = torch.to(x16, 6)\n",
      "  ret11 = torch.layer_norm(input28, [768], CONSTANTS.c76, CONSTANTS.c77)\n",
      "  input29 = torch.to(ret11, 5)\n",
      "  _85 = torch.add(torch.matmul(input29, CONSTANTS.c78), CONSTANTS.c79)\n",
      "  _86 = torch.sigmoid(torch.mul(_85, CONSTANTS.c19))\n",
      "  input30 = torch.mul(_85, _86)\n",
      "  _87 = torch.add(torch.matmul(input30, CONSTANTS.c80), CONSTANTS.c81)\n",
      "  x17 = torch.add(x16, _87)\n",
      "  input31 = torch.to(x17, 6)\n",
      "  ret12 = torch.layer_norm(input31, [768], CONSTANTS.c82, CONSTANTS.c83)\n",
      "  query5 = torch.to(ret12, 5)\n",
      "  _88 = torch.size(query5, 0)\n",
      "  _89 = torch.size(query5, 1)\n",
      "  bsz5 = ops.prim.NumToTensor(_89)\n",
      "  _90 = torch.size(query5, 2)\n",
      "  embed_dim5 = ops.prim.NumToTensor(_90)\n",
      "  head_dim5 = torch.div(embed_dim5, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _91 = int(head_dim5)\n",
      "  _92 = torch.add(torch.matmul(query5, CONSTANTS.c84), CONSTANTS.c85)\n",
      "  q17, k11, v11, = torch.chunk(_92, 3, -1)\n",
      "  _93 = torch.contiguous(q17)\n",
      "  _94 = int(torch.mul(bsz5, CONSTANTS.c9))\n",
      "  q18 = torch.transpose(torch.view(_93, [_88, _94, _91]), 0, 1)\n",
      "  _95 = torch.view(torch.contiguous(k11), [torch.size(k11, 0), _94, _91])\n",
      "  k12 = torch.transpose(_95, 0, 1)\n",
      "  _96 = torch.view(torch.contiguous(v11), [torch.size(v11, 0), _94, _91])\n",
      "  v12 = torch.transpose(_96, 0, 1)\n",
      "  q19 = torch.div(q18, CONSTANTS.c12)\n",
      "  input32 = torch.bmm(q19, torch.transpose(k12, -2, -1))\n",
      "  attn5 = torch.softmax(input32, -1, 6)\n",
      "  attn_output11 = torch.bmm(torch.to(attn5, 5), v12)\n",
      "  _97 = torch.contiguous(torch.transpose(attn_output11, 0, 1))\n",
      "  attn_output12 = torch.view(_97, [_88, _89, _90])\n",
      "  _98 = torch.matmul(attn_output12, CONSTANTS.c86)\n",
      "  x18 = torch.add(x17, torch.add(_98, CONSTANTS.c87))\n",
      "  input33 = torch.to(x18, 6)\n",
      "  ret13 = torch.layer_norm(input33, [768], CONSTANTS.c88, CONSTANTS.c89)\n",
      "  input34 = torch.to(ret13, 5)\n",
      "  _99 = torch.add(torch.matmul(input34, CONSTANTS.c90), CONSTANTS.c91)\n",
      "  _100 = torch.sigmoid(torch.mul(_99, CONSTANTS.c19))\n",
      "  input35 = torch.mul(_99, _100)\n",
      "  _101 = torch.add(torch.matmul(input35, CONSTANTS.c92), CONSTANTS.c93)\n",
      "  x19 = torch.add(x18, _101)\n",
      "  input36 = torch.to(x19, 6)\n",
      "  ret14 = torch.layer_norm(input36, [768], CONSTANTS.c94, CONSTANTS.c95)\n",
      "  query6 = torch.to(ret14, 5)\n",
      "  _102 = torch.size(query6, 0)\n",
      "  _103 = torch.size(query6, 1)\n",
      "  bsz6 = ops.prim.NumToTensor(_103)\n",
      "  _104 = torch.size(query6, 2)\n",
      "  embed_dim6 = ops.prim.NumToTensor(_104)\n",
      "  head_dim6 = torch.div(embed_dim6, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _105 = int(head_dim6)\n",
      "  _106 = torch.add(torch.matmul(query6, CONSTANTS.c96), CONSTANTS.c97)\n",
      "  q20, k13, v13, = torch.chunk(_106, 3, -1)\n",
      "  _107 = torch.contiguous(q20)\n",
      "  _108 = int(torch.mul(bsz6, CONSTANTS.c9))\n",
      "  q21 = torch.transpose(torch.view(_107, [_102, _108, _105]), 0, 1)\n",
      "  _109 = torch.view(torch.contiguous(k13), [torch.size(k13, 0), _108, _105])\n",
      "  k14 = torch.transpose(_109, 0, 1)\n",
      "  _110 = torch.view(torch.contiguous(v13), [torch.size(v13, 0), _108, _105])\n",
      "  v14 = torch.transpose(_110, 0, 1)\n",
      "  q22 = torch.div(q21, CONSTANTS.c12)\n",
      "  input37 = torch.bmm(q22, torch.transpose(k14, -2, -1))\n",
      "  attn6 = torch.softmax(input37, -1, 6)\n",
      "  attn_output13 = torch.bmm(torch.to(attn6, 5), v14)\n",
      "  _111 = torch.contiguous(torch.transpose(attn_output13, 0, 1))\n",
      "  attn_output14 = torch.view(_111, [_102, _103, _104])\n",
      "  _112 = torch.matmul(attn_output14, CONSTANTS.c98)\n",
      "  x20 = torch.add(x19, torch.add(_112, CONSTANTS.c99))\n",
      "  input38 = torch.to(x20, 6)\n",
      "  ret15 = torch.layer_norm(input38, [768], CONSTANTS.c100, CONSTANTS.c101)\n",
      "  input39 = torch.to(ret15, 5)\n",
      "  _113 = torch.add(torch.matmul(input39, CONSTANTS.c102), CONSTANTS.c103)\n",
      "  _114 = torch.sigmoid(torch.mul(_113, CONSTANTS.c19))\n",
      "  input40 = torch.mul(_113, _114)\n",
      "  _115 = torch.add(torch.matmul(input40, CONSTANTS.c104), CONSTANTS.c105)\n",
      "  x21 = torch.add(x20, _115)\n",
      "  input41 = torch.to(x21, 6)\n",
      "  ret16 = torch.layer_norm(input41, [768], CONSTANTS.c106, CONSTANTS.c107)\n",
      "  query7 = torch.to(ret16, 5)\n",
      "  _116 = torch.size(query7, 0)\n",
      "  _117 = torch.size(query7, 1)\n",
      "  bsz7 = ops.prim.NumToTensor(_117)\n",
      "  _118 = torch.size(query7, 2)\n",
      "  embed_dim7 = ops.prim.NumToTensor(_118)\n",
      "  head_dim7 = torch.div(embed_dim7, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _119 = int(head_dim7)\n",
      "  _120 = torch.add(torch.matmul(query7, CONSTANTS.c108), CONSTANTS.c109)\n",
      "  q23, k15, v15, = torch.chunk(_120, 3, -1)\n",
      "  _121 = torch.contiguous(q23)\n",
      "  _122 = int(torch.mul(bsz7, CONSTANTS.c9))\n",
      "  q24 = torch.transpose(torch.view(_121, [_116, _122, _119]), 0, 1)\n",
      "  _123 = torch.view(torch.contiguous(k15), [torch.size(k15, 0), _122, _119])\n",
      "  k16 = torch.transpose(_123, 0, 1)\n",
      "  _124 = torch.view(torch.contiguous(v15), [torch.size(v15, 0), _122, _119])\n",
      "  v16 = torch.transpose(_124, 0, 1)\n",
      "  q25 = torch.div(q24, CONSTANTS.c12)\n",
      "  input42 = torch.bmm(q25, torch.transpose(k16, -2, -1))\n",
      "  attn7 = torch.softmax(input42, -1, 6)\n",
      "  attn_output15 = torch.bmm(torch.to(attn7, 5), v16)\n",
      "  _125 = torch.contiguous(torch.transpose(attn_output15, 0, 1))\n",
      "  attn_output16 = torch.view(_125, [_116, _117, _118])\n",
      "  _126 = torch.matmul(attn_output16, CONSTANTS.c110)\n",
      "  x22 = torch.add(x21, torch.add(_126, CONSTANTS.c111))\n",
      "  input43 = torch.to(x22, 6)\n",
      "  ret17 = torch.layer_norm(input43, [768], CONSTANTS.c112, CONSTANTS.c113)\n",
      "  input44 = torch.to(ret17, 5)\n",
      "  _127 = torch.add(torch.matmul(input44, CONSTANTS.c114), CONSTANTS.c115)\n",
      "  _128 = torch.sigmoid(torch.mul(_127, CONSTANTS.c19))\n",
      "  input45 = torch.mul(_127, _128)\n",
      "  _129 = torch.add(torch.matmul(input45, CONSTANTS.c116), CONSTANTS.c117)\n",
      "  x23 = torch.add(x22, _129)\n",
      "  input46 = torch.to(x23, 6)\n",
      "  ret18 = torch.layer_norm(input46, [768], CONSTANTS.c118, CONSTANTS.c119)\n",
      "  query8 = torch.to(ret18, 5)\n",
      "  _130 = torch.size(query8, 0)\n",
      "  _131 = torch.size(query8, 1)\n",
      "  bsz8 = ops.prim.NumToTensor(_131)\n",
      "  _132 = torch.size(query8, 2)\n",
      "  embed_dim8 = ops.prim.NumToTensor(_132)\n",
      "  head_dim8 = torch.div(embed_dim8, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _133 = int(head_dim8)\n",
      "  _134 = torch.add(torch.matmul(query8, CONSTANTS.c120), CONSTANTS.c121)\n",
      "  q26, k17, v17, = torch.chunk(_134, 3, -1)\n",
      "  _135 = torch.contiguous(q26)\n",
      "  _136 = int(torch.mul(bsz8, CONSTANTS.c9))\n",
      "  q27 = torch.transpose(torch.view(_135, [_130, _136, _133]), 0, 1)\n",
      "  _137 = torch.view(torch.contiguous(k17), [torch.size(k17, 0), _136, _133])\n",
      "  k18 = torch.transpose(_137, 0, 1)\n",
      "  _138 = torch.view(torch.contiguous(v17), [torch.size(v17, 0), _136, _133])\n",
      "  v18 = torch.transpose(_138, 0, 1)\n",
      "  q28 = torch.div(q27, CONSTANTS.c12)\n",
      "  input47 = torch.bmm(q28, torch.transpose(k18, -2, -1))\n",
      "  attn8 = torch.softmax(input47, -1, 6)\n",
      "  attn_output17 = torch.bmm(torch.to(attn8, 5), v18)\n",
      "  _139 = torch.contiguous(torch.transpose(attn_output17, 0, 1))\n",
      "  attn_output18 = torch.view(_139, [_130, _131, _132])\n",
      "  _140 = torch.matmul(attn_output18, CONSTANTS.c122)\n",
      "  x24 = torch.add(x23, torch.add(_140, CONSTANTS.c123))\n",
      "  input48 = torch.to(x24, 6)\n",
      "  ret19 = torch.layer_norm(input48, [768], CONSTANTS.c124, CONSTANTS.c125)\n",
      "  input49 = torch.to(ret19, 5)\n",
      "  _141 = torch.add(torch.matmul(input49, CONSTANTS.c126), CONSTANTS.c127)\n",
      "  _142 = torch.sigmoid(torch.mul(_141, CONSTANTS.c19))\n",
      "  input50 = torch.mul(_141, _142)\n",
      "  _143 = torch.add(torch.matmul(input50, CONSTANTS.c128), CONSTANTS.c129)\n",
      "  x25 = torch.add(x24, _143)\n",
      "  input51 = torch.to(x25, 6)\n",
      "  ret20 = torch.layer_norm(input51, [768], CONSTANTS.c130, CONSTANTS.c131)\n",
      "  query9 = torch.to(ret20, 5)\n",
      "  _144 = torch.size(query9, 0)\n",
      "  _145 = torch.size(query9, 1)\n",
      "  bsz9 = ops.prim.NumToTensor(_145)\n",
      "  _146 = torch.size(query9, 2)\n",
      "  embed_dim9 = ops.prim.NumToTensor(_146)\n",
      "  head_dim9 = torch.div(embed_dim9, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _147 = int(head_dim9)\n",
      "  _148 = torch.add(torch.matmul(query9, CONSTANTS.c132), CONSTANTS.c133)\n",
      "  q29, k19, v19, = torch.chunk(_148, 3, -1)\n",
      "  _149 = torch.contiguous(q29)\n",
      "  _150 = int(torch.mul(bsz9, CONSTANTS.c9))\n",
      "  q30 = torch.transpose(torch.view(_149, [_144, _150, _147]), 0, 1)\n",
      "  _151 = torch.view(torch.contiguous(k19), [torch.size(k19, 0), _150, _147])\n",
      "  k20 = torch.transpose(_151, 0, 1)\n",
      "  _152 = torch.view(torch.contiguous(v19), [torch.size(v19, 0), _150, _147])\n",
      "  v20 = torch.transpose(_152, 0, 1)\n",
      "  q31 = torch.div(q30, CONSTANTS.c12)\n",
      "  input52 = torch.bmm(q31, torch.transpose(k20, -2, -1))\n",
      "  attn9 = torch.softmax(input52, -1, 6)\n",
      "  attn_output19 = torch.bmm(torch.to(attn9, 5), v20)\n",
      "  _153 = torch.contiguous(torch.transpose(attn_output19, 0, 1))\n",
      "  attn_output20 = torch.view(_153, [_144, _145, _146])\n",
      "  _154 = torch.matmul(attn_output20, CONSTANTS.c134)\n",
      "  x26 = torch.add(x25, torch.add(_154, CONSTANTS.c135))\n",
      "  input53 = torch.to(x26, 6)\n",
      "  ret21 = torch.layer_norm(input53, [768], CONSTANTS.c136, CONSTANTS.c137)\n",
      "  input54 = torch.to(ret21, 5)\n",
      "  _155 = torch.add(torch.matmul(input54, CONSTANTS.c138), CONSTANTS.c139)\n",
      "  _156 = torch.sigmoid(torch.mul(_155, CONSTANTS.c19))\n",
      "  input55 = torch.mul(_155, _156)\n",
      "  _157 = torch.add(torch.matmul(input55, CONSTANTS.c140), CONSTANTS.c141)\n",
      "  x27 = torch.add(x26, _157)\n",
      "  input56 = torch.to(x27, 6)\n",
      "  ret22 = torch.layer_norm(input56, [768], CONSTANTS.c142, CONSTANTS.c143)\n",
      "  query10 = torch.to(ret22, 5)\n",
      "  _158 = torch.size(query10, 0)\n",
      "  _159 = torch.size(query10, 1)\n",
      "  bsz10 = ops.prim.NumToTensor(_159)\n",
      "  _160 = torch.size(query10, 2)\n",
      "  embed_dim10 = ops.prim.NumToTensor(_160)\n",
      "  head_dim10 = torch.div(embed_dim10, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _161 = int(head_dim10)\n",
      "  _162 = torch.add(torch.matmul(query10, CONSTANTS.c144), CONSTANTS.c145)\n",
      "  q32, k21, v21, = torch.chunk(_162, 3, -1)\n",
      "  _163 = torch.contiguous(q32)\n",
      "  _164 = int(torch.mul(bsz10, CONSTANTS.c9))\n",
      "  q33 = torch.transpose(torch.view(_163, [_158, _164, _161]), 0, 1)\n",
      "  _165 = torch.view(torch.contiguous(k21), [torch.size(k21, 0), _164, _161])\n",
      "  k22 = torch.transpose(_165, 0, 1)\n",
      "  _166 = torch.view(torch.contiguous(v21), [torch.size(v21, 0), _164, _161])\n",
      "  v22 = torch.transpose(_166, 0, 1)\n",
      "  q34 = torch.div(q33, CONSTANTS.c12)\n",
      "  input57 = torch.bmm(q34, torch.transpose(k22, -2, -1))\n",
      "  attn10 = torch.softmax(input57, -1, 6)\n",
      "  attn_output21 = torch.bmm(torch.to(attn10, 5), v22)\n",
      "  _167 = torch.contiguous(torch.transpose(attn_output21, 0, 1))\n",
      "  attn_output22 = torch.view(_167, [_158, _159, _160])\n",
      "  _168 = torch.matmul(attn_output22, CONSTANTS.c146)\n",
      "  x28 = torch.add(x27, torch.add(_168, CONSTANTS.c147))\n",
      "  input58 = torch.to(x28, 6)\n",
      "  ret23 = torch.layer_norm(input58, [768], CONSTANTS.c148, CONSTANTS.c149)\n",
      "  input59 = torch.to(ret23, 5)\n",
      "  _169 = torch.add(torch.matmul(input59, CONSTANTS.c150), CONSTANTS.c151)\n",
      "  _170 = torch.sigmoid(torch.mul(_169, CONSTANTS.c19))\n",
      "  input60 = torch.mul(_169, _170)\n",
      "  _171 = torch.add(torch.matmul(input60, CONSTANTS.c152), CONSTANTS.c153)\n",
      "  x29 = torch.add(x28, _171)\n",
      "  x30 = torch.permute(x29, [1, 0, 2])\n",
      "  _172 = torch.slice(x30, 0, 0, 9223372036854775807)\n",
      "  x31 = torch.slice(torch.select(_172, 1, 0), 1, 0, 9223372036854775807)\n",
      "  input61 = torch.to(x31, 6)\n",
      "  ret24 = torch.layer_norm(input61, [768], CONSTANTS.c154, CONSTANTS.c155)\n",
      "  x32 = torch.to(ret24, 5)\n",
      "  input62 = torch.matmul(x32, CONSTANTS.c156)\n",
      "  _173 = torch.add(torch.matmul(input62, CONSTANTS.c157), CONSTANTS.c158)\n",
      "  input63 = torch.relu(_173)\n",
      "  _174 = torch.add(torch.matmul(input63, CONSTANTS.c159), CONSTANTS.c160)\n",
      "  return torch.softmax(_174, 1, 6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode(), torch.jit.optimized_execution(True):\n",
    "    traced_script_module = torch.jit.trace(wrp_model, image)\n",
    "    traced_script_module = torch.jit.optimize_for_inference(traced_script_module)\n",
    "\n",
    "print(traced_script_module.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH = \"car_angle_classifier_36/2/\"\n",
    "os.makedirs(OUT_PATH, exist_ok=True)\n",
    "\n",
    "traced_script_module.save(f\"{OUT_PATH}/model.pt\")\n",
    "traced_script_module = torch.jit.load(f\"{OUT_PATH}/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 36]) torch.float32\n",
      "CPU times: user 10.2 s, sys: 747 µs, total: 10.2 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "torch.cuda.synchronize()\n",
    "with torch.no_grad():\n",
    "    o = traced_script_module(image)\n",
    "torch.cuda.synchronize()\n",
    "print(o.shape, o.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: Trace new backbones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess = clip.load(CONFIG[\"clip_type\"], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedModel(torch.nn.Module):\n",
    "    def __init__(self,model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.mean = 255 * torch.tensor([0.48145466, 0.4578275, 0.40821073]).to(device).reshape(1,3,1,1)\n",
    "        self.std = 255 * torch.tensor([0.26862954, 0.26130258, 0.27577711]).to(device).reshape(1,3,1,1)\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def forward(self, data, fp16=True):\n",
    "        data = data.permute(0,3,1,2)\n",
    "        with amp.autocast(enabled=fp16):\n",
    "            data = data.sub(self.mean)\n",
    "            data = data.div_(self.std)\n",
    "            image_features = self.model.visual(data.to(self.model.dtype))\n",
    "            return image_features\n",
    "\n",
    "wrp_model = WrappedModel(model).eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randint(0,255,(256,224,224,3), dtype=torch.uint8, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1024]) torch.float16\n",
      "CPU times: user 144 ms, sys: 20 µs, total: 144 ms\n",
      "Wall time: 143 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "torch.cuda.synchronize()\n",
    "with torch.no_grad():\n",
    "    svd_out = wrp_model(data)\n",
    "torch.cuda.synchronize()\n",
    "print(svd_out.shape, svd_out.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    data: Tensor) -> Tensor:\n",
      "  data0 = torch.permute(data, [0, 3, 1, 2])\n",
      "  data1 = torch.sub(data0, CONSTANTS.c0)\n",
      "  data2 = torch.div_(data1, CONSTANTS.c1)\n",
      "  input = torch.to(data2, 5)\n",
      "  _0 = torch.conv2d(input, CONSTANTS.c2, None, [32, 32])\n",
      "  _1 = [torch.size(_0, 0), torch.size(_0, 1), -1]\n",
      "  x = torch.reshape(_0, _1)\n",
      "  x0 = torch.permute(x, [0, 2, 1])\n",
      "  _2 = [torch.size(x0, 0), 1, torch.size(x0, 2)]\n",
      "  _3 = torch.zeros(_2, dtype=5, layout=None, device=torch.device(\"cuda:0\"), pin_memory=False)\n",
      "  x1 = torch.cat([torch.add(CONSTANTS.c3, _3), x0], 1)\n",
      "  x2 = torch.add(x1, CONSTANTS.c4)\n",
      "  input0 = torch.to(x2, 6)\n",
      "  ret = torch.layer_norm(input0, [768], CONSTANTS.c5, CONSTANTS.c6)\n",
      "  x3 = torch.to(ret, 5)\n",
      "  x4 = torch.permute(x3, [1, 0, 2])\n",
      "  input1 = torch.to(x4, 6)\n",
      "  ret0 = torch.layer_norm(input1, [768], CONSTANTS.c7, CONSTANTS.c8)\n",
      "  query = torch.to(ret0, 5)\n",
      "  _4 = torch.size(query, 0)\n",
      "  _5 = torch.size(query, 1)\n",
      "  bsz = ops.prim.NumToTensor(_5)\n",
      "  _6 = torch.size(query, 2)\n",
      "  embed_dim = ops.prim.NumToTensor(_6)\n",
      "  head_dim = torch.div(embed_dim, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _7 = int(head_dim)\n",
      "  _8 = torch.add(torch.matmul(query, CONSTANTS.c10), CONSTANTS.c11)\n",
      "  q, k, v, = torch.chunk(_8, 3, -1)\n",
      "  _9 = torch.contiguous(q)\n",
      "  _10 = int(torch.mul(bsz, CONSTANTS.c9))\n",
      "  q0 = torch.transpose(torch.view(_9, [_4, _10, _7]), 0, 1)\n",
      "  _11 = torch.view(torch.contiguous(k), [torch.size(k, 0), _10, _7])\n",
      "  k0 = torch.transpose(_11, 0, 1)\n",
      "  _12 = torch.view(torch.contiguous(v), [torch.size(v, 0), _10, _7])\n",
      "  v0 = torch.transpose(_12, 0, 1)\n",
      "  q1 = torch.div(q0, CONSTANTS.c12)\n",
      "  input2 = torch.bmm(q1, torch.transpose(k0, -2, -1))\n",
      "  attn = torch.softmax(input2, -1, 6)\n",
      "  attn_output = torch.bmm(torch.to(attn, 5), v0)\n",
      "  _13 = torch.contiguous(torch.transpose(attn_output, 0, 1))\n",
      "  attn_output0 = torch.view(_13, [_4, _5, _6])\n",
      "  _14 = torch.matmul(attn_output0, CONSTANTS.c13)\n",
      "  x5 = torch.add(x4, torch.add(_14, CONSTANTS.c14))\n",
      "  input3 = torch.to(x5, 6)\n",
      "  ret1 = torch.layer_norm(input3, [768], CONSTANTS.c15, CONSTANTS.c16)\n",
      "  input4 = torch.to(ret1, 5)\n",
      "  _15 = torch.add(torch.matmul(input4, CONSTANTS.c17), CONSTANTS.c18)\n",
      "  _16 = torch.sigmoid(torch.mul(_15, CONSTANTS.c19))\n",
      "  input5 = torch.mul(_15, _16)\n",
      "  _17 = torch.add(torch.matmul(input5, CONSTANTS.c20), CONSTANTS.c21)\n",
      "  x6 = torch.add(x5, _17)\n",
      "  input6 = torch.to(x6, 6)\n",
      "  ret2 = torch.layer_norm(input6, [768], CONSTANTS.c22, CONSTANTS.c23)\n",
      "  query0 = torch.to(ret2, 5)\n",
      "  _18 = torch.size(query0, 0)\n",
      "  _19 = torch.size(query0, 1)\n",
      "  bsz0 = ops.prim.NumToTensor(_19)\n",
      "  _20 = torch.size(query0, 2)\n",
      "  embed_dim0 = ops.prim.NumToTensor(_20)\n",
      "  head_dim0 = torch.div(embed_dim0, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _21 = int(head_dim0)\n",
      "  _22 = torch.add(torch.matmul(query0, CONSTANTS.c24), CONSTANTS.c25)\n",
      "  q2, k1, v1, = torch.chunk(_22, 3, -1)\n",
      "  _23 = torch.contiguous(q2)\n",
      "  _24 = int(torch.mul(bsz0, CONSTANTS.c9))\n",
      "  q3 = torch.transpose(torch.view(_23, [_18, _24, _21]), 0, 1)\n",
      "  _25 = torch.view(torch.contiguous(k1), [torch.size(k1, 0), _24, _21])\n",
      "  k2 = torch.transpose(_25, 0, 1)\n",
      "  _26 = torch.view(torch.contiguous(v1), [torch.size(v1, 0), _24, _21])\n",
      "  v2 = torch.transpose(_26, 0, 1)\n",
      "  q4 = torch.div(q3, CONSTANTS.c12)\n",
      "  input7 = torch.bmm(q4, torch.transpose(k2, -2, -1))\n",
      "  attn0 = torch.softmax(input7, -1, 6)\n",
      "  attn_output1 = torch.bmm(torch.to(attn0, 5), v2)\n",
      "  _27 = torch.contiguous(torch.transpose(attn_output1, 0, 1))\n",
      "  attn_output2 = torch.view(_27, [_18, _19, _20])\n",
      "  _28 = torch.matmul(attn_output2, CONSTANTS.c26)\n",
      "  x7 = torch.add(x6, torch.add(_28, CONSTANTS.c27))\n",
      "  input8 = torch.to(x7, 6)\n",
      "  ret3 = torch.layer_norm(input8, [768], CONSTANTS.c28, CONSTANTS.c29)\n",
      "  input9 = torch.to(ret3, 5)\n",
      "  _29 = torch.add(torch.matmul(input9, CONSTANTS.c30), CONSTANTS.c31)\n",
      "  _30 = torch.sigmoid(torch.mul(_29, CONSTANTS.c19))\n",
      "  input10 = torch.mul(_29, _30)\n",
      "  _31 = torch.add(torch.matmul(input10, CONSTANTS.c32), CONSTANTS.c33)\n",
      "  x8 = torch.add(x7, _31)\n",
      "  input11 = torch.to(x8, 6)\n",
      "  ret4 = torch.layer_norm(input11, [768], CONSTANTS.c34, CONSTANTS.c35)\n",
      "  query1 = torch.to(ret4, 5)\n",
      "  _32 = torch.size(query1, 0)\n",
      "  _33 = torch.size(query1, 1)\n",
      "  bsz1 = ops.prim.NumToTensor(_33)\n",
      "  _34 = torch.size(query1, 2)\n",
      "  embed_dim1 = ops.prim.NumToTensor(_34)\n",
      "  head_dim1 = torch.div(embed_dim1, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _35 = int(head_dim1)\n",
      "  _36 = torch.add(torch.matmul(query1, CONSTANTS.c36), CONSTANTS.c37)\n",
      "  q5, k3, v3, = torch.chunk(_36, 3, -1)\n",
      "  _37 = torch.contiguous(q5)\n",
      "  _38 = int(torch.mul(bsz1, CONSTANTS.c9))\n",
      "  q6 = torch.transpose(torch.view(_37, [_32, _38, _35]), 0, 1)\n",
      "  _39 = torch.view(torch.contiguous(k3), [torch.size(k3, 0), _38, _35])\n",
      "  k4 = torch.transpose(_39, 0, 1)\n",
      "  _40 = torch.view(torch.contiguous(v3), [torch.size(v3, 0), _38, _35])\n",
      "  v4 = torch.transpose(_40, 0, 1)\n",
      "  q7 = torch.div(q6, CONSTANTS.c12)\n",
      "  input12 = torch.bmm(q7, torch.transpose(k4, -2, -1))\n",
      "  attn1 = torch.softmax(input12, -1, 6)\n",
      "  attn_output3 = torch.bmm(torch.to(attn1, 5), v4)\n",
      "  _41 = torch.contiguous(torch.transpose(attn_output3, 0, 1))\n",
      "  attn_output4 = torch.view(_41, [_32, _33, _34])\n",
      "  _42 = torch.matmul(attn_output4, CONSTANTS.c38)\n",
      "  x9 = torch.add(x8, torch.add(_42, CONSTANTS.c39))\n",
      "  input13 = torch.to(x9, 6)\n",
      "  ret5 = torch.layer_norm(input13, [768], CONSTANTS.c40, CONSTANTS.c41)\n",
      "  input14 = torch.to(ret5, 5)\n",
      "  _43 = torch.add(torch.matmul(input14, CONSTANTS.c42), CONSTANTS.c43)\n",
      "  _44 = torch.sigmoid(torch.mul(_43, CONSTANTS.c19))\n",
      "  input15 = torch.mul(_43, _44)\n",
      "  _45 = torch.add(torch.matmul(input15, CONSTANTS.c44), CONSTANTS.c45)\n",
      "  x10 = torch.add(x9, _45)\n",
      "  input16 = torch.to(x10, 6)\n",
      "  ret6 = torch.layer_norm(input16, [768], CONSTANTS.c46, CONSTANTS.c47)\n",
      "  query2 = torch.to(ret6, 5)\n",
      "  _46 = torch.size(query2, 0)\n",
      "  _47 = torch.size(query2, 1)\n",
      "  bsz2 = ops.prim.NumToTensor(_47)\n",
      "  _48 = torch.size(query2, 2)\n",
      "  embed_dim2 = ops.prim.NumToTensor(_48)\n",
      "  head_dim2 = torch.div(embed_dim2, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _49 = int(head_dim2)\n",
      "  _50 = torch.add(torch.matmul(query2, CONSTANTS.c48), CONSTANTS.c49)\n",
      "  q8, k5, v5, = torch.chunk(_50, 3, -1)\n",
      "  _51 = torch.contiguous(q8)\n",
      "  _52 = int(torch.mul(bsz2, CONSTANTS.c9))\n",
      "  q9 = torch.transpose(torch.view(_51, [_46, _52, _49]), 0, 1)\n",
      "  _53 = torch.view(torch.contiguous(k5), [torch.size(k5, 0), _52, _49])\n",
      "  k6 = torch.transpose(_53, 0, 1)\n",
      "  _54 = torch.view(torch.contiguous(v5), [torch.size(v5, 0), _52, _49])\n",
      "  v6 = torch.transpose(_54, 0, 1)\n",
      "  q10 = torch.div(q9, CONSTANTS.c12)\n",
      "  input17 = torch.bmm(q10, torch.transpose(k6, -2, -1))\n",
      "  attn2 = torch.softmax(input17, -1, 6)\n",
      "  attn_output5 = torch.bmm(torch.to(attn2, 5), v6)\n",
      "  _55 = torch.contiguous(torch.transpose(attn_output5, 0, 1))\n",
      "  attn_output6 = torch.view(_55, [_46, _47, _48])\n",
      "  _56 = torch.matmul(attn_output6, CONSTANTS.c50)\n",
      "  x11 = torch.add(x10, torch.add(_56, CONSTANTS.c51))\n",
      "  input18 = torch.to(x11, 6)\n",
      "  ret7 = torch.layer_norm(input18, [768], CONSTANTS.c52, CONSTANTS.c53)\n",
      "  input19 = torch.to(ret7, 5)\n",
      "  _57 = torch.add(torch.matmul(input19, CONSTANTS.c54), CONSTANTS.c55)\n",
      "  _58 = torch.sigmoid(torch.mul(_57, CONSTANTS.c19))\n",
      "  input20 = torch.mul(_57, _58)\n",
      "  _59 = torch.add(torch.matmul(input20, CONSTANTS.c56), CONSTANTS.c57)\n",
      "  x12 = torch.add(x11, _59)\n",
      "  input21 = torch.to(x12, 6)\n",
      "  ret8 = torch.layer_norm(input21, [768], CONSTANTS.c58, CONSTANTS.c59)\n",
      "  query3 = torch.to(ret8, 5)\n",
      "  _60 = torch.size(query3, 0)\n",
      "  _61 = torch.size(query3, 1)\n",
      "  bsz3 = ops.prim.NumToTensor(_61)\n",
      "  _62 = torch.size(query3, 2)\n",
      "  embed_dim3 = ops.prim.NumToTensor(_62)\n",
      "  head_dim3 = torch.div(embed_dim3, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _63 = int(head_dim3)\n",
      "  _64 = torch.add(torch.matmul(query3, CONSTANTS.c60), CONSTANTS.c61)\n",
      "  q11, k7, v7, = torch.chunk(_64, 3, -1)\n",
      "  _65 = torch.contiguous(q11)\n",
      "  _66 = int(torch.mul(bsz3, CONSTANTS.c9))\n",
      "  q12 = torch.transpose(torch.view(_65, [_60, _66, _63]), 0, 1)\n",
      "  _67 = torch.view(torch.contiguous(k7), [torch.size(k7, 0), _66, _63])\n",
      "  k8 = torch.transpose(_67, 0, 1)\n",
      "  _68 = torch.view(torch.contiguous(v7), [torch.size(v7, 0), _66, _63])\n",
      "  v8 = torch.transpose(_68, 0, 1)\n",
      "  q13 = torch.div(q12, CONSTANTS.c12)\n",
      "  input22 = torch.bmm(q13, torch.transpose(k8, -2, -1))\n",
      "  attn3 = torch.softmax(input22, -1, 6)\n",
      "  attn_output7 = torch.bmm(torch.to(attn3, 5), v8)\n",
      "  _69 = torch.contiguous(torch.transpose(attn_output7, 0, 1))\n",
      "  attn_output8 = torch.view(_69, [_60, _61, _62])\n",
      "  _70 = torch.matmul(attn_output8, CONSTANTS.c62)\n",
      "  x13 = torch.add(x12, torch.add(_70, CONSTANTS.c63))\n",
      "  input23 = torch.to(x13, 6)\n",
      "  ret9 = torch.layer_norm(input23, [768], CONSTANTS.c64, CONSTANTS.c65)\n",
      "  input24 = torch.to(ret9, 5)\n",
      "  _71 = torch.add(torch.matmul(input24, CONSTANTS.c66), CONSTANTS.c67)\n",
      "  _72 = torch.sigmoid(torch.mul(_71, CONSTANTS.c19))\n",
      "  input25 = torch.mul(_71, _72)\n",
      "  _73 = torch.add(torch.matmul(input25, CONSTANTS.c68), CONSTANTS.c69)\n",
      "  x14 = torch.add(x13, _73)\n",
      "  input26 = torch.to(x14, 6)\n",
      "  ret10 = torch.layer_norm(input26, [768], CONSTANTS.c70, CONSTANTS.c71)\n",
      "  query4 = torch.to(ret10, 5)\n",
      "  _74 = torch.size(query4, 0)\n",
      "  _75 = torch.size(query4, 1)\n",
      "  bsz4 = ops.prim.NumToTensor(_75)\n",
      "  _76 = torch.size(query4, 2)\n",
      "  embed_dim4 = ops.prim.NumToTensor(_76)\n",
      "  head_dim4 = torch.div(embed_dim4, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _77 = int(head_dim4)\n",
      "  _78 = torch.add(torch.matmul(query4, CONSTANTS.c72), CONSTANTS.c73)\n",
      "  q14, k9, v9, = torch.chunk(_78, 3, -1)\n",
      "  _79 = torch.contiguous(q14)\n",
      "  _80 = int(torch.mul(bsz4, CONSTANTS.c9))\n",
      "  q15 = torch.transpose(torch.view(_79, [_74, _80, _77]), 0, 1)\n",
      "  _81 = torch.view(torch.contiguous(k9), [torch.size(k9, 0), _80, _77])\n",
      "  k10 = torch.transpose(_81, 0, 1)\n",
      "  _82 = torch.view(torch.contiguous(v9), [torch.size(v9, 0), _80, _77])\n",
      "  v10 = torch.transpose(_82, 0, 1)\n",
      "  q16 = torch.div(q15, CONSTANTS.c12)\n",
      "  input27 = torch.bmm(q16, torch.transpose(k10, -2, -1))\n",
      "  attn4 = torch.softmax(input27, -1, 6)\n",
      "  attn_output9 = torch.bmm(torch.to(attn4, 5), v10)\n",
      "  _83 = torch.contiguous(torch.transpose(attn_output9, 0, 1))\n",
      "  attn_output10 = torch.view(_83, [_74, _75, _76])\n",
      "  _84 = torch.matmul(attn_output10, CONSTANTS.c74)\n",
      "  x15 = torch.add(x14, torch.add(_84, CONSTANTS.c75))\n",
      "  input28 = torch.to(x15, 6)\n",
      "  ret11 = torch.layer_norm(input28, [768], CONSTANTS.c76, CONSTANTS.c77)\n",
      "  input29 = torch.to(ret11, 5)\n",
      "  _85 = torch.add(torch.matmul(input29, CONSTANTS.c78), CONSTANTS.c79)\n",
      "  _86 = torch.sigmoid(torch.mul(_85, CONSTANTS.c19))\n",
      "  input30 = torch.mul(_85, _86)\n",
      "  _87 = torch.add(torch.matmul(input30, CONSTANTS.c80), CONSTANTS.c81)\n",
      "  x16 = torch.add(x15, _87)\n",
      "  input31 = torch.to(x16, 6)\n",
      "  ret12 = torch.layer_norm(input31, [768], CONSTANTS.c82, CONSTANTS.c83)\n",
      "  query5 = torch.to(ret12, 5)\n",
      "  _88 = torch.size(query5, 0)\n",
      "  _89 = torch.size(query5, 1)\n",
      "  bsz5 = ops.prim.NumToTensor(_89)\n",
      "  _90 = torch.size(query5, 2)\n",
      "  embed_dim5 = ops.prim.NumToTensor(_90)\n",
      "  head_dim5 = torch.div(embed_dim5, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _91 = int(head_dim5)\n",
      "  _92 = torch.add(torch.matmul(query5, CONSTANTS.c84), CONSTANTS.c85)\n",
      "  q17, k11, v11, = torch.chunk(_92, 3, -1)\n",
      "  _93 = torch.contiguous(q17)\n",
      "  _94 = int(torch.mul(bsz5, CONSTANTS.c9))\n",
      "  q18 = torch.transpose(torch.view(_93, [_88, _94, _91]), 0, 1)\n",
      "  _95 = torch.view(torch.contiguous(k11), [torch.size(k11, 0), _94, _91])\n",
      "  k12 = torch.transpose(_95, 0, 1)\n",
      "  _96 = torch.view(torch.contiguous(v11), [torch.size(v11, 0), _94, _91])\n",
      "  v12 = torch.transpose(_96, 0, 1)\n",
      "  q19 = torch.div(q18, CONSTANTS.c12)\n",
      "  input32 = torch.bmm(q19, torch.transpose(k12, -2, -1))\n",
      "  attn5 = torch.softmax(input32, -1, 6)\n",
      "  attn_output11 = torch.bmm(torch.to(attn5, 5), v12)\n",
      "  _97 = torch.contiguous(torch.transpose(attn_output11, 0, 1))\n",
      "  attn_output12 = torch.view(_97, [_88, _89, _90])\n",
      "  _98 = torch.matmul(attn_output12, CONSTANTS.c86)\n",
      "  x17 = torch.add(x16, torch.add(_98, CONSTANTS.c87))\n",
      "  input33 = torch.to(x17, 6)\n",
      "  ret13 = torch.layer_norm(input33, [768], CONSTANTS.c88, CONSTANTS.c89)\n",
      "  input34 = torch.to(ret13, 5)\n",
      "  _99 = torch.add(torch.matmul(input34, CONSTANTS.c90), CONSTANTS.c91)\n",
      "  _100 = torch.sigmoid(torch.mul(_99, CONSTANTS.c19))\n",
      "  input35 = torch.mul(_99, _100)\n",
      "  _101 = torch.add(torch.matmul(input35, CONSTANTS.c92), CONSTANTS.c93)\n",
      "  x18 = torch.add(x17, _101)\n",
      "  input36 = torch.to(x18, 6)\n",
      "  ret14 = torch.layer_norm(input36, [768], CONSTANTS.c94, CONSTANTS.c95)\n",
      "  query6 = torch.to(ret14, 5)\n",
      "  _102 = torch.size(query6, 0)\n",
      "  _103 = torch.size(query6, 1)\n",
      "  bsz6 = ops.prim.NumToTensor(_103)\n",
      "  _104 = torch.size(query6, 2)\n",
      "  embed_dim6 = ops.prim.NumToTensor(_104)\n",
      "  head_dim6 = torch.div(embed_dim6, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _105 = int(head_dim6)\n",
      "  _106 = torch.add(torch.matmul(query6, CONSTANTS.c96), CONSTANTS.c97)\n",
      "  q20, k13, v13, = torch.chunk(_106, 3, -1)\n",
      "  _107 = torch.contiguous(q20)\n",
      "  _108 = int(torch.mul(bsz6, CONSTANTS.c9))\n",
      "  q21 = torch.transpose(torch.view(_107, [_102, _108, _105]), 0, 1)\n",
      "  _109 = torch.view(torch.contiguous(k13), [torch.size(k13, 0), _108, _105])\n",
      "  k14 = torch.transpose(_109, 0, 1)\n",
      "  _110 = torch.view(torch.contiguous(v13), [torch.size(v13, 0), _108, _105])\n",
      "  v14 = torch.transpose(_110, 0, 1)\n",
      "  q22 = torch.div(q21, CONSTANTS.c12)\n",
      "  input37 = torch.bmm(q22, torch.transpose(k14, -2, -1))\n",
      "  attn6 = torch.softmax(input37, -1, 6)\n",
      "  attn_output13 = torch.bmm(torch.to(attn6, 5), v14)\n",
      "  _111 = torch.contiguous(torch.transpose(attn_output13, 0, 1))\n",
      "  attn_output14 = torch.view(_111, [_102, _103, _104])\n",
      "  _112 = torch.matmul(attn_output14, CONSTANTS.c98)\n",
      "  x19 = torch.add(x18, torch.add(_112, CONSTANTS.c99))\n",
      "  input38 = torch.to(x19, 6)\n",
      "  ret15 = torch.layer_norm(input38, [768], CONSTANTS.c100, CONSTANTS.c101)\n",
      "  input39 = torch.to(ret15, 5)\n",
      "  _113 = torch.add(torch.matmul(input39, CONSTANTS.c102), CONSTANTS.c103)\n",
      "  _114 = torch.sigmoid(torch.mul(_113, CONSTANTS.c19))\n",
      "  input40 = torch.mul(_113, _114)\n",
      "  _115 = torch.add(torch.matmul(input40, CONSTANTS.c104), CONSTANTS.c105)\n",
      "  x20 = torch.add(x19, _115)\n",
      "  input41 = torch.to(x20, 6)\n",
      "  ret16 = torch.layer_norm(input41, [768], CONSTANTS.c106, CONSTANTS.c107)\n",
      "  query7 = torch.to(ret16, 5)\n",
      "  _116 = torch.size(query7, 0)\n",
      "  _117 = torch.size(query7, 1)\n",
      "  bsz7 = ops.prim.NumToTensor(_117)\n",
      "  _118 = torch.size(query7, 2)\n",
      "  embed_dim7 = ops.prim.NumToTensor(_118)\n",
      "  head_dim7 = torch.div(embed_dim7, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _119 = int(head_dim7)\n",
      "  _120 = torch.add(torch.matmul(query7, CONSTANTS.c108), CONSTANTS.c109)\n",
      "  q23, k15, v15, = torch.chunk(_120, 3, -1)\n",
      "  _121 = torch.contiguous(q23)\n",
      "  _122 = int(torch.mul(bsz7, CONSTANTS.c9))\n",
      "  q24 = torch.transpose(torch.view(_121, [_116, _122, _119]), 0, 1)\n",
      "  _123 = torch.view(torch.contiguous(k15), [torch.size(k15, 0), _122, _119])\n",
      "  k16 = torch.transpose(_123, 0, 1)\n",
      "  _124 = torch.view(torch.contiguous(v15), [torch.size(v15, 0), _122, _119])\n",
      "  v16 = torch.transpose(_124, 0, 1)\n",
      "  q25 = torch.div(q24, CONSTANTS.c12)\n",
      "  input42 = torch.bmm(q25, torch.transpose(k16, -2, -1))\n",
      "  attn7 = torch.softmax(input42, -1, 6)\n",
      "  attn_output15 = torch.bmm(torch.to(attn7, 5), v16)\n",
      "  _125 = torch.contiguous(torch.transpose(attn_output15, 0, 1))\n",
      "  attn_output16 = torch.view(_125, [_116, _117, _118])\n",
      "  _126 = torch.matmul(attn_output16, CONSTANTS.c110)\n",
      "  x21 = torch.add(x20, torch.add(_126, CONSTANTS.c111))\n",
      "  input43 = torch.to(x21, 6)\n",
      "  ret17 = torch.layer_norm(input43, [768], CONSTANTS.c112, CONSTANTS.c113)\n",
      "  input44 = torch.to(ret17, 5)\n",
      "  _127 = torch.add(torch.matmul(input44, CONSTANTS.c114), CONSTANTS.c115)\n",
      "  _128 = torch.sigmoid(torch.mul(_127, CONSTANTS.c19))\n",
      "  input45 = torch.mul(_127, _128)\n",
      "  _129 = torch.add(torch.matmul(input45, CONSTANTS.c116), CONSTANTS.c117)\n",
      "  x22 = torch.add(x21, _129)\n",
      "  input46 = torch.to(x22, 6)\n",
      "  ret18 = torch.layer_norm(input46, [768], CONSTANTS.c118, CONSTANTS.c119)\n",
      "  query8 = torch.to(ret18, 5)\n",
      "  _130 = torch.size(query8, 0)\n",
      "  _131 = torch.size(query8, 1)\n",
      "  bsz8 = ops.prim.NumToTensor(_131)\n",
      "  _132 = torch.size(query8, 2)\n",
      "  embed_dim8 = ops.prim.NumToTensor(_132)\n",
      "  head_dim8 = torch.div(embed_dim8, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _133 = int(head_dim8)\n",
      "  _134 = torch.add(torch.matmul(query8, CONSTANTS.c120), CONSTANTS.c121)\n",
      "  q26, k17, v17, = torch.chunk(_134, 3, -1)\n",
      "  _135 = torch.contiguous(q26)\n",
      "  _136 = int(torch.mul(bsz8, CONSTANTS.c9))\n",
      "  q27 = torch.transpose(torch.view(_135, [_130, _136, _133]), 0, 1)\n",
      "  _137 = torch.view(torch.contiguous(k17), [torch.size(k17, 0), _136, _133])\n",
      "  k18 = torch.transpose(_137, 0, 1)\n",
      "  _138 = torch.view(torch.contiguous(v17), [torch.size(v17, 0), _136, _133])\n",
      "  v18 = torch.transpose(_138, 0, 1)\n",
      "  q28 = torch.div(q27, CONSTANTS.c12)\n",
      "  input47 = torch.bmm(q28, torch.transpose(k18, -2, -1))\n",
      "  attn8 = torch.softmax(input47, -1, 6)\n",
      "  attn_output17 = torch.bmm(torch.to(attn8, 5), v18)\n",
      "  _139 = torch.contiguous(torch.transpose(attn_output17, 0, 1))\n",
      "  attn_output18 = torch.view(_139, [_130, _131, _132])\n",
      "  _140 = torch.matmul(attn_output18, CONSTANTS.c122)\n",
      "  x23 = torch.add(x22, torch.add(_140, CONSTANTS.c123))\n",
      "  input48 = torch.to(x23, 6)\n",
      "  ret19 = torch.layer_norm(input48, [768], CONSTANTS.c124, CONSTANTS.c125)\n",
      "  input49 = torch.to(ret19, 5)\n",
      "  _141 = torch.add(torch.matmul(input49, CONSTANTS.c126), CONSTANTS.c127)\n",
      "  _142 = torch.sigmoid(torch.mul(_141, CONSTANTS.c19))\n",
      "  input50 = torch.mul(_141, _142)\n",
      "  _143 = torch.add(torch.matmul(input50, CONSTANTS.c128), CONSTANTS.c129)\n",
      "  x24 = torch.add(x23, _143)\n",
      "  input51 = torch.to(x24, 6)\n",
      "  ret20 = torch.layer_norm(input51, [768], CONSTANTS.c130, CONSTANTS.c131)\n",
      "  query9 = torch.to(ret20, 5)\n",
      "  _144 = torch.size(query9, 0)\n",
      "  _145 = torch.size(query9, 1)\n",
      "  bsz9 = ops.prim.NumToTensor(_145)\n",
      "  _146 = torch.size(query9, 2)\n",
      "  embed_dim9 = ops.prim.NumToTensor(_146)\n",
      "  head_dim9 = torch.div(embed_dim9, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _147 = int(head_dim9)\n",
      "  _148 = torch.add(torch.matmul(query9, CONSTANTS.c132), CONSTANTS.c133)\n",
      "  q29, k19, v19, = torch.chunk(_148, 3, -1)\n",
      "  _149 = torch.contiguous(q29)\n",
      "  _150 = int(torch.mul(bsz9, CONSTANTS.c9))\n",
      "  q30 = torch.transpose(torch.view(_149, [_144, _150, _147]), 0, 1)\n",
      "  _151 = torch.view(torch.contiguous(k19), [torch.size(k19, 0), _150, _147])\n",
      "  k20 = torch.transpose(_151, 0, 1)\n",
      "  _152 = torch.view(torch.contiguous(v19), [torch.size(v19, 0), _150, _147])\n",
      "  v20 = torch.transpose(_152, 0, 1)\n",
      "  q31 = torch.div(q30, CONSTANTS.c12)\n",
      "  input52 = torch.bmm(q31, torch.transpose(k20, -2, -1))\n",
      "  attn9 = torch.softmax(input52, -1, 6)\n",
      "  attn_output19 = torch.bmm(torch.to(attn9, 5), v20)\n",
      "  _153 = torch.contiguous(torch.transpose(attn_output19, 0, 1))\n",
      "  attn_output20 = torch.view(_153, [_144, _145, _146])\n",
      "  _154 = torch.matmul(attn_output20, CONSTANTS.c134)\n",
      "  x25 = torch.add(x24, torch.add(_154, CONSTANTS.c135))\n",
      "  input53 = torch.to(x25, 6)\n",
      "  ret21 = torch.layer_norm(input53, [768], CONSTANTS.c136, CONSTANTS.c137)\n",
      "  input54 = torch.to(ret21, 5)\n",
      "  _155 = torch.add(torch.matmul(input54, CONSTANTS.c138), CONSTANTS.c139)\n",
      "  _156 = torch.sigmoid(torch.mul(_155, CONSTANTS.c19))\n",
      "  input55 = torch.mul(_155, _156)\n",
      "  _157 = torch.add(torch.matmul(input55, CONSTANTS.c140), CONSTANTS.c141)\n",
      "  x26 = torch.add(x25, _157)\n",
      "  input56 = torch.to(x26, 6)\n",
      "  ret22 = torch.layer_norm(input56, [768], CONSTANTS.c142, CONSTANTS.c143)\n",
      "  query10 = torch.to(ret22, 5)\n",
      "  _158 = torch.size(query10, 0)\n",
      "  _159 = torch.size(query10, 1)\n",
      "  bsz10 = ops.prim.NumToTensor(_159)\n",
      "  _160 = torch.size(query10, 2)\n",
      "  embed_dim10 = ops.prim.NumToTensor(_160)\n",
      "  head_dim10 = torch.div(embed_dim10, CONSTANTS.c9, rounding_mode=\"trunc\")\n",
      "  _161 = int(head_dim10)\n",
      "  _162 = torch.add(torch.matmul(query10, CONSTANTS.c144), CONSTANTS.c145)\n",
      "  q32, k21, v21, = torch.chunk(_162, 3, -1)\n",
      "  _163 = torch.contiguous(q32)\n",
      "  _164 = int(torch.mul(bsz10, CONSTANTS.c9))\n",
      "  q33 = torch.transpose(torch.view(_163, [_158, _164, _161]), 0, 1)\n",
      "  _165 = torch.view(torch.contiguous(k21), [torch.size(k21, 0), _164, _161])\n",
      "  k22 = torch.transpose(_165, 0, 1)\n",
      "  _166 = torch.view(torch.contiguous(v21), [torch.size(v21, 0), _164, _161])\n",
      "  v22 = torch.transpose(_166, 0, 1)\n",
      "  q34 = torch.div(q33, CONSTANTS.c12)\n",
      "  input57 = torch.bmm(q34, torch.transpose(k22, -2, -1))\n",
      "  attn10 = torch.softmax(input57, -1, 6)\n",
      "  attn_output21 = torch.bmm(torch.to(attn10, 5), v22)\n",
      "  _167 = torch.contiguous(torch.transpose(attn_output21, 0, 1))\n",
      "  attn_output22 = torch.view(_167, [_158, _159, _160])\n",
      "  _168 = torch.matmul(attn_output22, CONSTANTS.c146)\n",
      "  x27 = torch.add(x26, torch.add(_168, CONSTANTS.c147))\n",
      "  input58 = torch.to(x27, 6)\n",
      "  ret23 = torch.layer_norm(input58, [768], CONSTANTS.c148, CONSTANTS.c149)\n",
      "  input59 = torch.to(ret23, 5)\n",
      "  _169 = torch.add(torch.matmul(input59, CONSTANTS.c150), CONSTANTS.c151)\n",
      "  _170 = torch.sigmoid(torch.mul(_169, CONSTANTS.c19))\n",
      "  input60 = torch.mul(_169, _170)\n",
      "  _171 = torch.add(torch.matmul(input60, CONSTANTS.c152), CONSTANTS.c153)\n",
      "  x28 = torch.add(x27, _171)\n",
      "  x29 = torch.permute(x28, [1, 0, 2])\n",
      "  _172 = torch.slice(x29, 0, 0, 9223372036854775807)\n",
      "  x30 = torch.slice(torch.select(_172, 1, 0), 1, 0, 9223372036854775807)\n",
      "  input61 = torch.to(x30, 6)\n",
      "  ret24 = torch.layer_norm(input61, [768], CONSTANTS.c154, CONSTANTS.c155)\n",
      "  x31 = torch.to(ret24, 5)\n",
      "  return torch.matmul(x31, CONSTANTS.c156)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode(), torch.jit.optimized_execution(True):\n",
    "    traced_script_module = torch.jit.trace(wrp_model, data)\n",
    "    traced_script_module = torch.jit.optimize_for_inference(traced_script_module)\n",
    "print(traced_script_module.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH = f\"trace_{CONFIG['clip_type']}\"\n",
    "os.makedirs(OUT_PATH, exist_ok=True)\n",
    "\n",
    "traced_script_module.save(f\"{OUT_PATH}/model.pt\")\n",
    "traced_script_module = torch.jit.load(f\"{OUT_PATH}/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 512]) torch.float16\n",
      "CPU times: user 82.4 ms, sys: 0 ns, total: 82.4 ms\n",
      "Wall time: 81.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "torch.cuda.synchronize()\n",
    "with torch.inference_mode():\n",
    "    o = traced_script_module(data)\n",
    "torch.cuda.synchronize()\n",
    "print(o.shape, o.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(o.cpu().numpy(), svd_out.cpu().numpy(), rtol=1e-5, atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
